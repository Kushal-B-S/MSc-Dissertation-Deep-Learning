# üî¨ Comprehensive Deep Learning Exploration - MSc Dissertation

## üèÜ Key Achievements
- **Distinction** awarded for dissertation & overall MSc in AI
- **98/100** in Deep Learning module


Executed an end-to-end deep learning research pipeline:
- **Theoretical Foundations**: Mastered core concepts through implementation of forward/backpropagation, activation functions, and loss computations from first principles
- **Architecture Design**: Experimented with diverse network topologies (ANNs, CNNs) and modern architectures (ResNet, Inception, MobileNet)
- **Hyperparameter Optimization**: Systematically tested learning rates (0.001-0.6), batch sizes, weight initialization methods, and regularization techniques
- **Performance Tuning**: Implemented advanced optimization including learning rate scheduling, gradient clipping, and adaptive moment estimation

**Applied Research Outcome**: Developed a production-grade face mask detection system achieving **99.5% accuracy** through:
- Transfer learning with fine-tuned ImageNet models
- Active learning for efficient data utilization
- Comprehensive evaluation metrics (precision, recall, ROC-AUC)

## üß† Core Technical Components

### üîç Deep Learning Techniques Implemented
- **Fundamentals**:
  - Built ANNs/CNNs from scratch (NumPy)
  - Implemented forward/backpropagation manually
  - Custom weight initialization (He, Xavier/Glorot)

- **Optimization**:
  - Tested SGD, Momentum, RMSprop, Adam
  - Learning rate experimentation (0.001-0.6)
  - Regularization (L1/L2, Dropout, BatchNorm)

- **Advanced Architectures**:
  - Transfer learning with ResNet50/VGG16/InceptionV3
  - Active learning implementation
  - Conformal predictions

### üìä Performance Highlights
| Model Type       | Accuracy | Precision | Recall |
|------------------|----------|-----------|--------|
| Custom CNN       | 96%      | 0.95      | 0.96   |
| InceptionV3 (TL) | 99.5%    | 0.99      | 1.00   |
| MobileNetV2      | 99.1%    | 0.99      | 0.99   |

### üí° Key Insights
1. CNNs outperformed ANNs by **9% accuracy**
2. **BatchNorm** was most effective regularization
3. **InceptionV3** achieved perfect recall
4. Active learning reduced required training samples by **30%**

## üõ†Ô∏è Technology Stack
- **Frameworks**: TensorFlow, Keras, PyTorch
- **Optimization**: AdamW, Learning Rate Scheduling
- **Visualization**: Matplotlib, Seaborn
- **Evaluation**: scikit-learn metrics

## üìà Future Directions
- Real-time edge deployment
- Mask fit detection (nose/mouth coverage)
- Federated learning for privacy-preserving training

_Dissertation awarded distinction at Royal Holloway, University of London_
